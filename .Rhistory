dVtvec[i] <- AtBtVt$dVt[1] + (i-1)*abs(AtBtVt$dVt[1]-AtBtVt$dVt[2])/5
}
dVtvec2 <- c()
dVtvec2[1] <- AtBtVt$dVt[1]
for (i in 2:11) {
dVtvec2[i] <- AtBtVt$dVt[1] + (i-1)*abs(AtBtVt$dVt[1]-AtBtVt$dVt[2])/10
}
for (i in 12:21) {
dVtvec2[i] <- AtBtVt$dVt[2] + (i-11)*abs(AtBtVt$dVt[2]-AtBtVt$dVt[3])/10
}
uxtemp <- ux[11:13]
uxvec <- c()
uxvec[1] <- uxtemp[1]
for (i in 2:6) {
uxvec[i] <- uxtemp[1] + (i-1)*abs(uxtemp[1]-uxtemp[2])/5
}
uxvec2 <- c()
uxvec2[1] <- uxtemp[1]
for (i in 2:11) {
uxvec2[i] <- uxtemp[1] + (i-1)*abs(uxtemp[1]-uxtemp[2])/10
}
for (i in 12:21) {
uxvec2[i] <- uxtemp[2] + (i-11)*abs(uxtemp[2]-uxtemp[3])/10
}
uppg4data <- data.frame(dVt = dVtvec, u = uxvec)
uppg5data <- data.frame(dVt = dVtvec2, u = uxvec2)
Vt4 <- uppg4data %>% mutate(Vt = (dVt+u*50000 - P)/(0.027+u)) %>% select(Vt)
Vt4 <- Vt4 %>% mutate(age = c(50:55))
Vt4 <- round(Vt4[,c(2,1)], 3)
Vt5 <- uppg5data %>% mutate(Vt = (dVt+u*50000 - P)/(0.027+u)) %>% select(Vt)
Vt5 <- Vt5 %>% mutate(age = seq(50,60, by = 0.5))
Vt5 <- round(Vt5[,c(2,1)], 3)
AtBtVt <- round(AtBtVt, 3)
data45table <- Vt5
data45table[3] <- c(Vt4[1,2], "*", Vt4[2,2], "*", Vt4[3,2], "*",
Vt4[4,2], "*", Vt4[5,2], "*", Vt4[6,2], "*",
"*", "*", "*", "*", "*", "*", "*", "*", "*")
data45table[4] <- c(AtBtVt[1,5], "*", "*", "*", "*",
"*", "*", "*", "*", "*", AtBtVt[2,5], "*", "*",
"*", "*", "*", "*", "*", "*", "*", AtBtVt[3,5])
colnames(data45table) <- c("Age", "h=1", "h=0.5", "Vt")
knitr::kable(data45table, caption = "Värdefunktionen beräknade med Thieles för steglängd 0.5 och 1 samt Vt beräknat med At och Bt")
library(dplyr)
library(ggplot2)
library(VGAM)
data <- read.table("Wine/wine.data", sep = ",")
#Data on form (group,x_1,x_2)
Linear <- function(data){
colnames(data) <- c("V1","V2","V3")
#average group
agroup <- (min(data[,1])+max(data[,1]))/2
library(lattice)
with(data, xyplot(V3 ~ V2,groups = V1, col=c('blue', 'orange')))
# now fit two models
# model 1: linear regression
lmfits <- lm(V1 ~ V2 + V3 , data = data)
# get the slope and intercept for the decision boundary
#Intercept -1.5 because are groups 1 and 2
intercept <- -(lmfits$coef[1] - agroup) / lmfits$coef[3]
slope <- - lmfits$coef[2] / lmfits$coef[3]
# Figure 2.1
xyplot(V3 ~ V2, groups = V1, col = c('blue', 'orange'), data = data,
panel = function(...)
{
panel.xyplot(...)
panel.abline(intercept, slope)
},
main = 'Linear Regression of 1/2 Response')
}
kNearest <- function(data, k = 15){
colnames(data) <- c("V1","V2","V3")
# model2: k nearest-neighbor methods
library(class)
# get the range of x1 and x2
rx1 <- range(data$V2)
rx2 <- range(data$V3)
# get lattice points in predictor space
px1 <- seq(from = rx1[1], to = rx1[2], by = 0.05 )
px2 <- seq(from = rx2[1], to = rx2[2], by = 0.05 )
xnew <- expand.grid(x1 = px1, x2 = px2)
# get the contour map
knn15 <- knn(train = data[,2:3], test = xnew, cl = data[,1], k = k, prob = TRUE)
prob <- attr(knn15, "prob")
#toString() was just "1" in 0/1 case
prob <- ifelse(knn15==toString(max(data[,1])), prob, 1-prob)
prob15 <- matrix(prob, nrow = length(px1), ncol = length(px2))
# Figure 2.2
par(mar = rep(2,4))
contour(px1, px2, prob15, levels=0.5, labels="", xlab="", ylab="", main=
"15-nearest neighbour", axes=FALSE)
points(data[,2:3], col=ifelse(data[,1]==max(data[,1]), "coral", "cornflowerblue"))
points(xnew, pch=".", cex=1.2, col=ifelse(prob15>0.5, "coral", "cornflowerblue"))
box()
}
data <- as.data.frame(data)
datanew <- data %>% filter(V1!=1) %>% dplyr::select(V1,V2,V3)
library(dplyr)
getwd()
data <- read.table("Statistical learning/Project/Wine/wine.data", sep = ",")
library(dplyr)
library(ggplot2)
library(VGAM)
data <- read.table("Statistical learning/Project/Wine/wine.data", sep = ",")
#Data on form (group,x_1,x_2)
Linear <- function(data){
colnames(data) <- c("V1","V2","V3")
#average group
agroup <- (min(data[,1])+max(data[,1]))/2
library(lattice)
with(data, xyplot(V3 ~ V2,groups = V1, col=c('blue', 'orange')))
# now fit two models
# model 1: linear regression
lmfits <- lm(V1 ~ V2 + V3 , data = data)
# get the slope and intercept for the decision boundary
#Intercept -1.5 because are groups 1 and 2
intercept <- -(lmfits$coef[1] - agroup) / lmfits$coef[3]
slope <- - lmfits$coef[2] / lmfits$coef[3]
# Figure 2.1
xyplot(V3 ~ V2, groups = V1, col = c('blue', 'orange'), data = data,
panel = function(...)
{
panel.xyplot(...)
panel.abline(intercept, slope)
},
main = 'Linear Regression of 1/2 Response')
}
kNearest <- function(data, k = 15){
colnames(data) <- c("V1","V2","V3")
# model2: k nearest-neighbor methods
library(class)
# get the range of x1 and x2
rx1 <- range(data$V2)
rx2 <- range(data$V3)
# get lattice points in predictor space
px1 <- seq(from = rx1[1], to = rx1[2], by = 0.05 )
px2 <- seq(from = rx2[1], to = rx2[2], by = 0.05 )
xnew <- expand.grid(x1 = px1, x2 = px2)
# get the contour map
knn15 <- knn(train = data[,2:3], test = xnew, cl = data[,1], k = k, prob = TRUE)
prob <- attr(knn15, "prob")
#toString() was just "1" in 0/1 case
prob <- ifelse(knn15==toString(max(data[,1])), prob, 1-prob)
prob15 <- matrix(prob, nrow = length(px1), ncol = length(px2))
# Figure 2.2
par(mar = rep(2,4))
contour(px1, px2, prob15, levels=0.5, labels="", xlab="", ylab="", main=
"15-nearest neighbour", axes=FALSE)
points(data[,2:3], col=ifelse(data[,1]==max(data[,1]), "coral", "cornflowerblue"))
points(xnew, pch=".", cex=1.2, col=ifelse(prob15>0.5, "coral", "cornflowerblue"))
box()
}
data <- as.data.frame(data)
datanew <- data %>% filter(V1!=1) %>% dplyr::select(V1,V2,V3)
Linear(datanew)
kNearest(datanew, k=15)
Linear(datanew)
setwd("C:/Users/maxlu/iCloudDrive/Documents/Kurser/MasterThesis/BayesianOptimalPortfolio")
# This script includes functions that....
library(tidyquant)
library(plotly)
library(tidyverse)
library(timetk)
# get list of names from a imported yahoo portfolio
source("getNamesFinance.R")
stockNames <- getNames("Data/quotes.csv")
tick <- stockNames[-1] %>% head(29) %>% str_sort()
#download price data
price_data <- tq_get(tick,
from = '2020-06-29',
to = '2020-12-29',
get = 'stock.prices')
price_data[,-c(1,2)] <- na.approx(price_data[,-c(1,2)])
# Calculate daily returns for assets
ret_data <- price_data %>%
group_by(symbol) %>%
tq_transmute(select = adjusted,
mutate_fun = periodReturn,
period = "daily",
col_rename = "ret")
# Wide format
ret_data_wide <- ret_data %>%
spread(symbol, value = ret) %>%
tk_xts()
ret_data_wide
#Test one portfolio to look for errors
#################
mean_ret <- colMeans(ret_data_wide)
mean_ret
# multiply to annualize
cov_mat <- cov(ret_data_wide)*252
wts <- runif(n = length(tick))
wts <- wts/sum(wts)
port_returns <- (sum(wts * mean_ret) + 1)^252 - 1
print(port_returns)
port_risk <- sqrt(t(wts) %*% (cov_mat %*% wts))
print(port_risk)
# Column vector of ones
ones <- t(t(rep(1, length(tick))))
denominator <- t(ones)%*%solve(cov_mat)%*%ones
weights <- (solve(cov_mat)%*%ones)/(as.double(denominator))
((sum(mean_ret*weights)+1)^252)-1
sqrt(t(weights) %*% (cov_mat %*% weights))
# Number of portfolios
num_port <- 100000
all_wts <- matrix(nrow = num_port,
ncol = length(tick))
port_returns <- vector('numeric', length = num_port)
port_risk <- vector('numeric', length = num_port)
sharpe_ratio <- vector('numeric', length = num_port)
# For loop over random portfolios to
for (i in seq_along(port_returns)) {
wts <- runif(length(tick))
wts <- wts/sum(wts)
wts
# Storing weight in the matrix
all_wts[i,] <- wts
# Portfolio returns
port_ret <- sum(wts * mean_ret)
port_ret <- ((port_ret + 1)^252) - 1
# Storing Portfolio Returns values
port_returns[i] <- port_ret
# Creating and storing portfolio risk
port_sd <- sqrt(t(wts) %*% (cov_mat  %*% wts))
port_risk[i] <- port_sd
# Creating and storing Portfolio Sharpe Ratios
# Assuming 0% Risk free rate
sr <- port_ret/port_sd
sharpe_ratio[i] <- sr
}
# Storing the values in the table
portfolio_values <- tibble(Return = port_returns,
Risk = port_risk,
SharpeRatio = sharpe_ratio)
# Converting matrix to a tibble and changing column names
all_wts <- tk_tbl(all_wts)
colnames(all_wts) <- colnames(ret_data_wide)
# Combing all the values together
portfolio_values <- tk_tbl(cbind(all_wts, portfolio_values))
min_var <- portfolio_values[which.min(portfolio_values$Risk),]
max_sr <- portfolio_values[which.max(portfolio_values$SharpeRatio),]
# Plot Minimum Variance
p <- min_var %>%
gather(as.factor(tick[1]):as.factor(tick[length(tick)]), key = Asset,
value = Weights) %>%
mutate(Asset = as.factor(Asset)) %>%
ggplot(aes(x = fct_reorder(Asset,Weights), y = Weights, fill = Asset)) +
geom_bar(stat = 'identity') +
theme_minimal() +
labs(x = 'Assets', y = 'Weights', title = "Minimum Variance Portfolio Weights") +
scale_y_continuous(labels = scales::percent)
ggplotly(p)
tick <- stockNames[-1] %>% head(8) %>% str_sort()
#download price data
price_data <- tq_get(tick,
from = '2020-06-29',
to = '2020-12-29',
get = 'stock.prices')
price_data[,-c(1,2)] <- na.approx(price_data[,-c(1,2)])
# Calculate daily returns for assets
ret_data <- price_data %>%
group_by(symbol) %>%
tq_transmute(select = adjusted,
mutate_fun = periodReturn,
period = "daily",
col_rename = "ret")
# Wide format
ret_data_wide <- ret_data %>%
spread(symbol, value = ret) %>%
tk_xts()
#Test one portfolio to look for errors
#################
mean_ret <- colMeans(ret_data_wide)
mean_ret
# multiply to annualize
cov_mat <- cov(ret_data_wide)*252
wts <- runif(n = length(tick))
wts <- wts/sum(wts)
port_returns <- (sum(wts * mean_ret) + 1)^252 - 1
print(port_returns)
port_risk <- sqrt(t(wts) %*% (cov_mat %*% wts))
print(port_risk)
# Column vector of ones
ones <- t(t(rep(1, length(tick))))
denominator <- t(ones)%*%solve(cov_mat)%*%ones
weights <- (solve(cov_mat)%*%ones)/(as.double(denominator))
((sum(mean_ret*weights)+1)^252)-1
sqrt(t(weights) %*% (cov_mat %*% weights))
# Number of portfolios
num_port <- 100000
all_wts <- matrix(nrow = num_port,
ncol = length(tick))
port_returns <- vector('numeric', length = num_port)
port_risk <- vector('numeric', length = num_port)
sharpe_ratio <- vector('numeric', length = num_port)
# For loop over random portfolios to
for (i in seq_along(port_returns)) {
wts <- runif(length(tick))
wts <- wts/sum(wts)
wts
# Storing weight in the matrix
all_wts[i,] <- wts
# Portfolio returns
port_ret <- sum(wts * mean_ret)
port_ret <- ((port_ret + 1)^252) - 1
# Storing Portfolio Returns values
port_returns[i] <- port_ret
# Creating and storing portfolio risk
port_sd <- sqrt(t(wts) %*% (cov_mat  %*% wts))
port_risk[i] <- port_sd
# Creating and storing Portfolio Sharpe Ratios
# Assuming 0% Risk free rate
sr <- port_ret/port_sd
sharpe_ratio[i] <- sr
}
# Storing the values in the table
portfolio_values <- tibble(Return = port_returns,
Risk = port_risk,
SharpeRatio = sharpe_ratio)
# Converting matrix to a tibble and changing column names
all_wts <- tk_tbl(all_wts)
colnames(all_wts) <- colnames(ret_data_wide)
# Combing all the values together
portfolio_values <- tk_tbl(cbind(all_wts, portfolio_values))
min_var <- portfolio_values[which.min(portfolio_values$Risk),]
max_sr <- portfolio_values[which.max(portfolio_values$SharpeRatio),]
# Plot Minimum Variance
p <- min_var %>%
gather(as.factor(tick[1]):as.factor(tick[length(tick)]), key = Asset,
value = Weights) %>%
mutate(Asset = as.factor(Asset)) %>%
ggplot(aes(x = fct_reorder(Asset,Weights), y = Weights, fill = Asset)) +
geom_bar(stat = 'identity') +
theme_minimal() +
labs(x = 'Assets', y = 'Weights', title = "Minimum Variance Portfolio Weights") +
scale_y_continuous(labels = scales::percent)
ggplotly(p)
cov_mat
# Plot Tangent
p <- max_sr %>%
gather(as.factor(tick[1]):as.factor(tick[length(tick)]), key = Asset,
value = Weights) %>%
mutate(Asset = as.factor(Asset)) %>%
ggplot(aes(x = fct_reorder(Asset,Weights), y = Weights, fill = Asset)) +
geom_bar(stat = 'identity') +
theme_minimal() +
labs(x = 'Assets', y = 'Weights', title = "Tangency Portfolio Weights") +
scale_y_continuous(labels = scales::percent)
ggplotly(p)
p <- portfolio_values %>%
ggplot(aes(x = Risk, y = Return, color = SharpeRatio)) +
geom_point() +
theme_classic() +
scale_y_continuous(labels = scales::percent) +
scale_x_continuous(labels = scales::percent) +
labs(x = 'Annualized Risk',
y = 'Annualized Returns',
title = "Portfolio Optimization & Efficient Frontier") +
geom_point(aes(x = Risk,
y = Return), data = min_var, color = 'red') +
geom_point(aes(x = Risk,
y = Return), data = max_sr, color = 'red') #+
ggplotly(p)
cov_mat
# Number of portfolios
num_port <- 1000
all_wts <- matrix(nrow = num_port,
ncol = length(tick))
port_returns <- vector('numeric', length = num_port)
port_risk <- vector('numeric', length = num_port)
sharpe_ratio <- vector('numeric', length = num_port)
# For loop over random portfolios to
for (i in seq_along(port_returns)) {
wts <- runif(length(tick))
wts <- wts/sum(wts)
wts
# Storing weight in the matrix
all_wts[i,] <- wts
# Portfolio returns
port_ret <- sum(wts * mean_ret)
port_ret <- ((port_ret + 1)^252) - 1
# Storing Portfolio Returns values
port_returns[i] <- port_ret
# Creating and storing portfolio risk
port_sd <- sqrt(t(wts) %*% (cov_mat  %*% wts))
port_risk[i] <- port_sd
# Creating and storing Portfolio Sharpe Ratios
# Assuming 0% Risk free rate
sr <- port_ret/port_sd
sharpe_ratio[i] <- sr
}
# Storing the values in the table
portfolio_values <- tibble(Return = port_returns,
Risk = port_risk,
SharpeRatio = sharpe_ratio)
# Converting matrix to a tibble and changing column names
all_wts <- tk_tbl(all_wts)
colnames(all_wts) <- colnames(ret_data_wide)
# Combing all the values together
portfolio_values <- tk_tbl(cbind(all_wts, portfolio_values))
min_var <- portfolio_values[which.min(portfolio_values$Risk),]
max_sr <- portfolio_values[which.max(portfolio_values$SharpeRatio),]
# Plot Minimum Variance
p <- min_var %>%
gather(as.factor(tick[1]):as.factor(tick[length(tick)]), key = Asset,
value = Weights) %>%
mutate(Asset = as.factor(Asset)) %>%
ggplot(aes(x = fct_reorder(Asset,Weights), y = Weights, fill = Asset)) +
geom_bar(stat = 'identity') +
theme_minimal() +
labs(x = 'Assets', y = 'Weights', title = "Minimum Variance Portfolio Weights") +
scale_y_continuous(labels = scales::percent)
ggplotly(p)
# Plot Tangent
p <- max_sr %>%
gather(as.factor(tick[1]):as.factor(tick[length(tick)]), key = Asset,
value = Weights) %>%
mutate(Asset = as.factor(Asset)) %>%
ggplot(aes(x = fct_reorder(Asset,Weights), y = Weights, fill = Asset)) +
geom_bar(stat = 'identity') +
theme_minimal() +
labs(x = 'Assets', y = 'Weights', title = "Tangency Portfolio Weights") +
scale_y_continuous(labels = scales::percent)
ggplotly(p)
p <- portfolio_values %>%
ggplot(aes(x = Risk, y = Return, color = SharpeRatio)) +
geom_point() +
theme_classic() +
scale_y_continuous(labels = scales::percent) +
scale_x_continuous(labels = scales::percent) +
labs(x = 'Annualized Risk',
y = 'Annualized Returns',
title = "Portfolio Optimization & Efficient Frontier") +
geom_point(aes(x = Risk,
y = Return), data = min_var, color = 'red') +
geom_point(aes(x = Risk,
y = Return), data = max_sr, color = 'red') #+
ggplotly(p)
# Number of portfolios
num_port <- 10000
all_wts <- matrix(nrow = num_port,
ncol = length(tick))
port_returns <- vector('numeric', length = num_port)
port_risk <- vector('numeric', length = num_port)
sharpe_ratio <- vector('numeric', length = num_port)
# For loop over random portfolios to
for (i in seq_along(port_returns)) {
wts <- runif(length(tick))
wts <- wts/sum(wts)
wts
# Storing weight in the matrix
all_wts[i,] <- wts
# Portfolio returns
port_ret <- sum(wts * mean_ret)
port_ret <- ((port_ret + 1)^252) - 1
# Storing Portfolio Returns values
port_returns[i] <- port_ret
# Creating and storing portfolio risk
port_sd <- sqrt(t(wts) %*% (cov_mat  %*% wts))
port_risk[i] <- port_sd
# Creating and storing Portfolio Sharpe Ratios
# Assuming 0% Risk free rate
sr <- port_ret/port_sd
sharpe_ratio[i] <- sr
}
# Storing the values in the table
portfolio_values <- tibble(Return = port_returns,
Risk = port_risk,
SharpeRatio = sharpe_ratio)
# Converting matrix to a tibble and changing column names
all_wts <- tk_tbl(all_wts)
colnames(all_wts) <- colnames(ret_data_wide)
# Combing all the values together
portfolio_values <- tk_tbl(cbind(all_wts, portfolio_values))
min_var <- portfolio_values[which.min(portfolio_values$Risk),]
max_sr <- portfolio_values[which.max(portfolio_values$SharpeRatio),]
# Plot Minimum Variance
p <- min_var %>%
gather(as.factor(tick[1]):as.factor(tick[length(tick)]), key = Asset,
value = Weights) %>%
mutate(Asset = as.factor(Asset)) %>%
ggplot(aes(x = fct_reorder(Asset,Weights), y = Weights, fill = Asset)) +
geom_bar(stat = 'identity') +
theme_minimal() +
labs(x = 'Assets', y = 'Weights', title = "Minimum Variance Portfolio Weights") +
scale_y_continuous(labels = scales::percent)
ggplotly(p)
# Plot Tangent
p <- max_sr %>%
gather(as.factor(tick[1]):as.factor(tick[length(tick)]), key = Asset,
value = Weights) %>%
mutate(Asset = as.factor(Asset)) %>%
ggplot(aes(x = fct_reorder(Asset,Weights), y = Weights, fill = Asset)) +
geom_bar(stat = 'identity') +
theme_minimal() +
labs(x = 'Assets', y = 'Weights', title = "Tangency Portfolio Weights") +
scale_y_continuous(labels = scales::percent)
ggplotly(p)
p <- portfolio_values %>%
ggplot(aes(x = Risk, y = Return, color = SharpeRatio)) +
geom_point() +
theme_classic() +
scale_y_continuous(labels = scales::percent) +
scale_x_continuous(labels = scales::percent) +
labs(x = 'Annualized Risk',
y = 'Annualized Returns',
title = "Portfolio Optimization & Efficient Frontier") +
geom_point(aes(x = Risk,
y = Return), data = min_var, color = 'red') +
geom_point(aes(x = Risk,
y = Return), data = max_sr, color = 'red') #+
ggplotly(p)
View(ret_data)
